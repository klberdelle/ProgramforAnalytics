{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Gross & Sentiment\n",
    "### Group 9 Final Project - DNSC 6211\n",
    "\n",
    "Team Members:\n",
    "* Kelly Berdelle\n",
    "* Jason Houghton\n",
    "* Yuebo Li\n",
    "* Qinya Wang\n",
    "* Gaoshuang Zhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "\n",
    "* Problem Statement\n",
    "* Data Sources\n",
    "* Python Procedures\n",
    "* R Shiny Visualizations\n",
    "* Conclusions with Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: \n",
    "Can the box office success of a movie indicate the future sentiment of that movie?\n",
    "\n",
    "If future sentiment can be predicted, then movie studios will be able to use that information to forecast future earnings and use that information for long-term licensing deals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis:\n",
    "There will be a positive relationship between the financial success of a movie at time of release and future sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:\n",
    "To test our hypothesis, we will compile a list of the top 200 movies by gross, adjusted for inflation to 2016 dollars.  We will then conduct a sentiment analysis on twitter for each of these movies as a marker for current sentiment.  We will determine the relationship between box office success and future sentiment by comparing the ajusted gross income to the sentiment score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scrape the movie data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found a list of the top 200 movies ranked by gross, adjusted for inflation to 2016 dollars, at the following website: http://www.boxofficemojo.com/alltime/adjusted.htm.\n",
    "\n",
    "We scraped the information from this website into a data frame including columns for Ranking, Movie Title, Studio, Adjusted Gross, Unadjusted Gross, and Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scrape website for movie gross data\n",
    "def scrapeBoxOffice():\n",
    "    \"\"\"\n",
    "    Function to scrape data from BoxOfficeMojo\n",
    "    Inputs: None\n",
    "    Output: None\n",
    "    Returns data frame containing search results\n",
    "    \"\"\"\n",
    "    pageResults = []\n",
    "        \n",
    "    # Generate url\n",
    "    fullUrl = 'http://www.boxofficemojo.com/alltime/adjusted.htm'\n",
    "    \n",
    "    # Read results from url into Beautiful Soup\n",
    "    try:\n",
    "        soup = BeautifulSoup(urllib.request.urlopen(fullUrl).read(), 'lxml')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        return []\n",
    "        \n",
    "    body = soup.find('div', {'id': 'body'})\n",
    "    \n",
    "    mainTable = body.findAll('table', recursive=False)[1].tr.td.table\n",
    "    \n",
    "    rows = mainTable.findAll('tr')\n",
    "    firstRow = True\n",
    "    \n",
    "    for row in rows:\n",
    "        if firstRow == False:\n",
    "            \n",
    "            pageResult = {\n",
    "                'Ranking': '',\n",
    "                'Movie Title': '',\n",
    "                'Studio': '',\n",
    "                'Adjusted Gross': '',\n",
    "                'Unadjusted Gross': '',\n",
    "                'Year': '',\n",
    "                }\n",
    "                \n",
    "            cols = row.findAll('td')\n",
    "            pageResult['Ranking'] = cols[0].font.get_text(strip=True)\n",
    "            pageResult['Movie Title'] = cols[1].font.a.b.get_text(strip=True)\n",
    "            pageResult['Studio'] = cols[2].font.a.get_text(strip=True)\n",
    "            pageResult['Adjusted Gross'] = cols[3].font.b.get_text(strip=True)\n",
    "            pageResult['Unadjusted Gross'] = cols[4].font.get_text(strip=True)\n",
    "            pageResult['Year'] = cols[5].font.get_text(strip=True)\n",
    "            if pageResult['Unadjusted Gross'] == '2016':\n",
    "                pageResult['Year'] = '2016'\n",
    "                pageResult['Unadjusted Gross'] = pageResult['Adjusted Gross']\n",
    "            pageResults.append(pageResult)\n",
    "        firstRow = False   \n",
    "    df = pd.DataFrame(pageResults, columns=['Ranking', 'Movie Title', 'Studio', 'Adjusted Gross', 'Unadjusted Gross', 'Year'])\n",
    "    df['Adjusted Gross'].replace(regex=True, inplace=True, to_replace=r'\\D', value=r'')\n",
    "    df['Unadjusted Gross'].replace(regex=True, inplace=True, to_replace=r'\\D', value=r'')\n",
    "    df['Year'].replace(regex=True, inplace=True, to_replace=r'\\D', value=r'')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call the function to scrape the gross movie data\n",
    "results = scrapeBoxOffice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get a sentiment score for the top 200 highest grossing movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used tweepy to gather tweets containing the title of each movie in our data frame. Each tweet was cleaned, and a sentiment score was conducted.  A column was added to our data frame for Sentiment Score.  The resulting data frame was then written to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAuthData():\n",
    "    \"\"\"\n",
    "    Input: None\n",
    "    Returns: User's twitter authorization data\n",
    "    \"\"\"\n",
    "    with open('authdata.csv', 'r') as f: # When running replace 'authdata.csv' with user auth data file.\n",
    "        reader = csv.reader(f)\n",
    "        your_list = list(reader)\n",
    "\n",
    "    authdata = {}   \n",
    "    for element in your_list:\n",
    "        authdata[element[0]] = element[1]\n",
    "\n",
    "    return authdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweets(searchTerm):\n",
    "    \"\"\"\n",
    "    Input: Term to be searched in Twitter (movie title)\n",
    "    Returns: A string containing all of the resulting Tweets\n",
    "    \"\"\"\n",
    "    authdata = getAuthData()\n",
    "\n",
    "    CONSUMER_KEY = authdata['CONSUMER_KEY']\n",
    "    CONSUMER_SECRET = authdata['CONSUMER_SECRET']\n",
    "    OAUTH_TOKEN = authdata['OAUTH_TOKEN']\n",
    "    OAUTH_TOKEN_SECRET = authdata['OAUTH_TOKEN_SECRET']\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    public_tweets = tweepy.Cursor(api.search, q=searchTerm).items(100)\n",
    "\n",
    "    results= []\n",
    "\n",
    "    for tweet in public_tweets:\n",
    "        results.append(tweet.text)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(tweetString):\n",
    "    \"\"\"\n",
    "    Input: String containing Tweets\n",
    "    Returns: String containing Tweets without punctuation markings\n",
    "    \"\"\"\n",
    "    punctuation = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    s_sans_punct = \"\"\n",
    "    for letter in tweetString:\n",
    "        if (letter not in punctuation) and (letter in \"abcdefghijklmnopqrstuvwxyz \"):\n",
    "            s_sans_punct += letter\n",
    "    return s_sans_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLowerCaseText(status_texts):\n",
    "    \"\"\"\n",
    "    Input: String containing Tweets\n",
    "    Returns: String containing Tweets in all lower case letters\n",
    "    \"\"\"\n",
    "    lowered_texts = []\n",
    "    for texts in status_texts:\n",
    "        try: \n",
    "            mytext = str(texts.lower())\n",
    "            lowered_texts.append(mytext)\n",
    "        except:\n",
    "            pass\n",
    "    return lowered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCleanedTweets(lowered_texts):\n",
    "    \"\"\"\n",
    "    Input: String containing Tweets\n",
    "    Returns: String containing cleaned Tweets\n",
    "    \"\"\"\n",
    "    cleanedTweets = []\n",
    "    for text in lowered_texts:\n",
    "        wordlist = str(text).split()\n",
    "        wordlist_nopun = [ str(remove_punctuation(for_a_word)) for for_a_word in wordlist ]\n",
    "        cleanedTweets.append(wordlist_nopun)\n",
    "    return cleanedTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(CleanedTweet):\n",
    "    \"\"\"\n",
    "    Input: String containing cleaned Tweets\n",
    "    Returns: A formatted score for the string of cleaned Tweets\n",
    "    \"\"\"\n",
    "    strCT = []\n",
    "    for i in CleanedTweet:\n",
    "        strCT.append(' '.join(i))\n",
    "    score= []     \n",
    "    for j in strCT:\n",
    "        analysis = TextBlob(j)\n",
    "        score.append(analysis.sentiment.polarity)\n",
    "    FormatScore = []\n",
    "    for x in score:\n",
    "        x = 50*(x+1)\n",
    "        FormatScore.append(x)\n",
    "    return FormatScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweepySentiment(searchTerm):\n",
    "    \"\"\"\n",
    "    Input: Term to be searched in Twitter (movie title)\n",
    "    Returns: Sentiment score for the search term (movie title)\n",
    "    \"\"\"\n",
    "    # Counter to enact a time delay in order to avoid searching for too many Tweets in a fixed amount of time.\n",
    "    global tweetCount\n",
    "    if tweetCount > 650:\n",
    "        time.sleep(60*16)\n",
    "        tweetCount = 0\n",
    "    # Executes functions to get Tweets, clean them, and produce a sentiment score\n",
    "    movieTweets = getTweets(searchTerm)\n",
    "    tweetCount += len(movieTweets)\n",
    "    movieTweetsLCT = getLowerCaseText(movieTweets)\n",
    "    cleanedMovieTweets = getCleanedTweets(movieTweetsLCT)\n",
    "    movieScore = score(cleanedMovieTweets)\n",
    "    sentimentScore = np.mean(movieScore)\n",
    "    \n",
    "    return sentimentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare to get tweets and sentiments\n",
    "tweetCount = 0\n",
    "# Create a new column in the data frame for sentiment score\n",
    "results['Sentiment Score'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gather Tweets, conduct sentiment anlaysis, and add results to the data frame for each movie in the data frame\n",
    "for movie in results['Movie Title']:\n",
    "    results['Sentiment Score'][results['Movie Title'] == movie] = tweepySentiment(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write dataframe to a csv file\n",
    "results.to_csv('BoxOfficeSentiment.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
